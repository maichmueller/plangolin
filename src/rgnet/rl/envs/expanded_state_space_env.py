import abc
from collections import defaultdict
from typing import Dict, List, Optional, Tuple

import pymimir as mi
import torch

from rgnet.rl.envs.planning_env import InstanceReplacementStrategy, PlanningEnvironment


class ResetStrategy(metaclass=abc.ABCMeta):

    @abc.abstractmethod
    def __call__(self, space: mi.StateSpace) -> mi.State:
        pass


class InitialStateReset(ResetStrategy):

    def __call__(self, space: mi.StateSpace):
        return space.get_initial_state()


class UniformRandomReset(ResetStrategy):
    def __call__(self, space: mi.StateSpace):
        return space.sample_state()


class WeightedRandomReset(InstanceReplacementStrategy):

    def __init__(
        self,
        all_instances: List[mi.StateSpace],
        generator: Optional[torch.Generator] = None,
    ):
        total_states = sum(space.num_states() for space in all_instances)
        self.weights = torch.tensor(
            [space.num_states() / total_states for space in all_instances]
        )
        self.all_instances = all_instances
        self.generator = generator
        super().__init__(all_instances)

    def __call__(self, index: int) -> mi.StateSpace:
        index = torch.multinomial(
            self.weights, 1, replacement=True, generator=self.generator
        ).item()
        return self.all_instances[index]


class IteratingReset(ResetStrategy):
    """
    Iterate over each state in the space in cycles.
    For each space separate counters are stores.
    """

    def __init__(self):
        super().__init__()
        self.idx_per_space: Dict[mi.StateSpace, int] = defaultdict(int)

    def __call__(self, space: mi.StateSpace) -> mi.State:
        idx = self.idx_per_space[space]
        self.idx_per_space[space] = (idx + 1) % space.num_states()
        return space.get_states()[idx]


class MultiInstanceStateSpaceEnv(PlanningEnvironment[mi.StateSpace]):

    def __init__(
        self,
        spaces: List[mi.StateSpace],
        reset_strategy: ResetStrategy = InitialStateReset(),
        batch_size: torch.Size = torch.Size((1,)),
        seed: Optional[int] = None,
        device: str = "cpu",
    ):
        self.reset_strategy = reset_strategy
        super().__init__(
            all_instances=spaces, batch_size=batch_size, seed=seed, device=device
        )

    def transitions_for(
        self, active_instance: mi.StateSpace, state: mi.State
    ) -> List[mi.Transition]:
        return active_instance.get_forward_transitions(state)

    def initial_for(
        self, active_instances: mi.StateSpace
    ) -> Tuple[mi.State, List[mi.Literal]]:
        return (
            self.reset_strategy(active_instances),
            active_instances.problem.goal,
        )

    def is_goal(self, active_instance: mi.StateSpace, state) -> bool:
        return active_instance.is_goal_state(state)


class ExpandedStateSpaceEnv(MultiInstanceStateSpaceEnv):
    """
    ExpandedStateSpaceEnv defines the MDP environment from a problem's full state space
     as generated by pymimir.
    """

    def __init__(
        self,
        space: mi.StateSpace,
        batch_size: torch.Size,
        **kwargs,
    ):
        PlanningEnvironment.assert_1D_batch(batch_size)
        batch_size_ = batch_size[0]
        self._initial_state = space.get_initial_state()
        self.problem = space.problem

        super().__init__(spaces=[space] * batch_size_, batch_size=batch_size, **kwargs)
