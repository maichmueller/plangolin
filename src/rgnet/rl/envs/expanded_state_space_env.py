import abc
from collections import defaultdict
from typing import Dict, Iterable, List, Optional, Tuple

import torch
from tensordict import tensordict
from torchrl.data.utils import DEVICE_TYPING

import xmimir as xmi
from rgnet.rl.envs.planning_env import InstanceReplacementStrategy, PlanningEnvironment
from rgnet.rl.reward import RewardFunction, UnitReward
from xmimir import XState


class ResetStrategy(metaclass=abc.ABCMeta):
    @abc.abstractmethod
    def __call__(self, space: xmi.XStateSpace) -> xmi.XState:
        pass


class InitialStateReset(ResetStrategy):
    def __call__(self, space: xmi.XStateSpace):
        return space.initial_state


class UniformRandomReset(ResetStrategy):
    def __init__(self, generator: Optional[torch.Generator] = None):
        self.generator = generator

    def __call__(self, space: xmi.XStateSpace):
        return space[
            torch.randint(0, len(space), size=(1,), generator=self.generator).item()
        ]


class WeightedRandomReset(InstanceReplacementStrategy):
    def __init__(
        self,
        all_instances: List[xmi.XStateSpace],
        generator: Optional[torch.Generator] = None,
    ):
        total_states = sum(len(space) for space in all_instances)
        self.weights = torch.tensor(
            [len(space) / total_states for space in all_instances]
        )
        self.all_instances = all_instances
        self.generator = generator
        super().__init__(all_instances)

    def __call__(self, index: int) -> xmi.XStateSpace:
        index = torch.multinomial(
            self.weights, 1, replacement=True, generator=self.generator
        ).item()
        return self.all_instances[index]


class IteratingReset(ResetStrategy):
    """
    Iterate over each state in the space in cycles.
    For each space separate counters are stores.
    """

    def __init__(self):
        super().__init__()
        self.idx_per_space: Dict[xmi.XStateSpace, int] = defaultdict(int)

    def __call__(self, space: xmi.XStateSpace) -> xmi.XState:
        idx = self.idx_per_space[space]
        self.idx_per_space[space] = (idx + 1) % len(space)
        return space.get_state(idx)


class MultiInstanceStateSpaceEnv(PlanningEnvironment[xmi.XStateSpace]):
    def __init__(
        self,
        spaces: List[xmi.XStateSpace],
        reset_strategy: ResetStrategy = InitialStateReset(),
        batch_size: torch.Size | int | Iterable[int] = 1,
        seed: Optional[int] = None,
        device: DEVICE_TYPING = "cpu",
        keys: PlanningEnvironment.AcceptedKeys = PlanningEnvironment.default_keys,
        reward_function: RewardFunction = UnitReward(gamma=0.9),
        **kwargs,
    ):
        self.reset_strategy = reset_strategy
        super().__init__(
            all_instances=spaces,
            batch_size=batch_size,
            seed=seed,
            device=device,
            keys=keys,
            reward_function=reward_function,
            **kwargs,
        )

    def transitions_for(
        self, active_instance: xmi.XStateSpace, state: xmi.XState
    ) -> List[xmi.XTransition]:
        return list(active_instance.forward_transitions(state))

    def initial_for(
        self, active_instances: xmi.XStateSpace
    ) -> Tuple[xmi.XState, tuple[xmi.XLiteral, ...]]:
        return (
            self.reset_strategy(active_instances),
            active_instances.problem.goal(),
        )

    def is_goal(self, active_instance: xmi.XStateSpace, state: XState) -> bool:
        return active_instance.is_goal(state)

    def traverse(self, *spaces: xmi.XStateSpace) -> list[tensordict]:
        return [
            ExpandedStateSpaceEnv(
                active_instance,
                batch_size=torch.Size((len(active_instance),)),
                reset_strategy=IteratingReset(),
                reward_function=self.reward_function,
            ).reset(autoreset=False)
            for active_instance in (spaces or self._all_instances)
        ]


class ExpandedStateSpaceEnv(MultiInstanceStateSpaceEnv):
    """
    ExpandedStateSpaceEnv defines the MDP environment from a problem's full state space
     as generated by xmimir.
    """

    def __init__(
        self,
        space: xmi.XStateSpace,
        batch_size: torch.Size | int | Iterable[int] = 1,
        **kwargs,
    ):
        batch_size = PlanningEnvironment.assert_1d_batch(batch_size)
        batch_size_ = batch_size[0]
        super().__init__(spaces=[space] * batch_size_, batch_size=batch_size, **kwargs)
