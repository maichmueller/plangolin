import abc
from collections import defaultdict
from typing import Dict, List, Optional, Tuple

import torch
from torchrl.data.utils import DEVICE_TYPING

import xmimir as xmi
from rgnet.rl.envs.planning_env import InstanceReplacementStrategy, PlanningEnvironment
from xmimir import XState


class ResetStrategy(metaclass=abc.ABCMeta):
    @abc.abstractmethod
    def __call__(self, space: xmi.XStateSpace) -> xmi.XState:
        pass


class InitialStateReset(ResetStrategy):
    def __call__(self, space: xmi.XStateSpace):
        return space.initial_state()


class UniformRandomReset(ResetStrategy):
    def __init__(self, generator: Optional[torch.Generator] = None):
        self.generator = generator

    def __call__(self, space: xmi.XStateSpace):
        return space[
            torch.randint(0, len(space), size=(1,), generator=self.generator).item()
        ]


class WeightedRandomReset(InstanceReplacementStrategy):
    def __init__(
        self,
        all_instances: List[xmi.XStateSpace],
        generator: Optional[torch.Generator] = None,
    ):
        total_states = sum(len(space) for space in all_instances)
        self.weights = torch.tensor(
            [len(space) / total_states for space in all_instances]
        )
        self.all_instances = all_instances
        self.generator = generator
        super().__init__(all_instances)

    def __call__(self, index: int) -> xmi.XStateSpace:
        index = torch.multinomial(
            self.weights, 1, replacement=True, generator=self.generator
        ).item()
        return self.all_instances[index]


class IteratingReset(ResetStrategy):
    """
    Iterate over each state in the space in cycles.
    For each space separate counters are stores.
    """

    def __init__(self):
        super().__init__()
        self.idx_per_space: Dict[xmi.XStateSpace, int] = defaultdict(int)

    def __call__(self, space: xmi.XStateSpace) -> xmi.XState:
        idx = self.idx_per_space[space]
        self.idx_per_space[space] = (idx + 1) % len(space)
        return space.get_state(idx)


class MultiInstanceStateSpaceEnv(PlanningEnvironment[xmi.XStateSpace]):
    def __init__(
        self,
        spaces: List[xmi.XStateSpace],
        reset_strategy: ResetStrategy = InitialStateReset(),
        batch_size: torch.Size = torch.Size((1,)),
        seed: Optional[int] = None,
        device: DEVICE_TYPING = "cpu",
        keys: PlanningEnvironment.AcceptedKeys = PlanningEnvironment.default_keys,
        custom_dead_end_reward: Optional[float] = None,
    ):
        self.reset_strategy = reset_strategy
        super().__init__(
            all_instances=spaces,
            batch_size=batch_size,
            seed=seed,
            device=device,
            keys=keys,
            custom_dead_end_reward=custom_dead_end_reward,
        )

    def transitions_for(
        self, active_instance: xmi.XStateSpace, state: xmi.XState
    ) -> List[xmi.XTransition]:
        return list(active_instance.forward_transitions(state))

    def initial_for(
        self, active_instances: xmi.XStateSpace
    ) -> Tuple[xmi.XState, List[xmi.XLiteral]]:
        return (
            self.reset_strategy(active_instances),
            list(active_instances.problem.goal()),
        )

    def is_goal(self, active_instance: xmi.XStateSpace, state: XState) -> bool:
        return active_instance.is_goal(state)


class ExpandedStateSpaceEnv(MultiInstanceStateSpaceEnv):
    """
    ExpandedStateSpaceEnv defines the MDP environment from a problem's full state space
     as generated by xmimir.
    """

    def __init__(
        self,
        space: xmi.XStateSpace,
        batch_size: torch.Size,
        **kwargs,
    ):
        PlanningEnvironment.assert_1D_batch(batch_size)
        batch_size_ = batch_size[0]
        self._initial_state = space.initial_state()
        self.problem = space.problem

        super().__init__(spaces=[space] * batch_size_, batch_size=batch_size, **kwargs)
